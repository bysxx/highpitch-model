{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067651dc1ad349c8a0661bc67c760771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9404ccafcf4c91b54a1d1857f0f239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686d3cd9375443ffb02611c4350dd96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/214 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77c00e4a4054f3d9362d7ebb86e0677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a03fbf5dc74491ea7698d5e14d76dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/554 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee8cd0884d045c0aedbe6433bbb8f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/30.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94cbf7ea7ba648ada76dd50bfc70086c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "model_id = 'hongseongpil/Wav2Vec2.0_zeroth_Ko'\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_id,output_attentions=True)\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tokenize_Kor import decompose_tokens\n",
    "import torch\n",
    "from pydub.effects import normalize\n",
    "from pydub import AudioSegment \n",
    "from pydub.silence import detect_nonsilent\n",
    "import numpy as np\n",
    "def getAudioInput(source_path):\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(source_path).set_frame_rate(16000).set_sample_width(2).set_channels(1)\n",
    "        if(audio.duration_seconds > 10):\n",
    "            audio = audio[0:1000*10]\n",
    "        result = detect_nonsilent(audio,min_silence_len=200,silence_thresh=-60)\n",
    "        newaudio = AudioSegment.empty()\n",
    "        for index in result:\n",
    "            newaudio += audio[index[0]:index[1]]\n",
    "        newaudio = normalize(newaudio)\n",
    "        return newaudio\n",
    "    except Exception as e:\n",
    "        print(\"오류 발생:\", e)\n",
    "def PrintAudioInfo(audio):\n",
    "    channels = audio.channels\n",
    "    sample_rate = audio.frame_rate\n",
    "    print(\"Channels:\", channels)\n",
    "    print(\"Sample rate:\", sample_rate)\n",
    "    print(\"Duration: \", audio.duration_seconds)\n",
    "    print(\"Bit depth:\", audio.sample_width, \"bits\") \n",
    "    print(\"len samples:\", len(np.array(audio.get_array_of_samples())))\n",
    "    display(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zx288\\AppData\\Local\\Temp\\ipykernel_16852\\1999888468.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_values = torch.tensor(input).unsqueeze(0)\n"
     ]
    }
   ],
   "source": [
    "audio_input = getAudioInput(\"test1.wav\")\n",
    "model.eval()\n",
    "input = processor(np.array(audio_input.get_array_of_samples(),dtype=np.float32), sampling_rate=16000, return_tensors=\"pt\").input_values[0]\n",
    "with torch.no_grad():\n",
    "    input_values = torch.tensor(input).unsqueeze(0)\n",
    "    logits = model(input_values).logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12.5506,  4.3925,  3.6470]) ㅇ\n",
      "tensor([11.7529,  5.2504,  4.4889]) ㅡ\n",
      "tensor([15.0512,  0.9118,  0.3162]) [PAD]\n",
      "tensor([12.6545,  4.7039,  3.7945]) ㅁ\n",
      "tensor([14.2822,  2.3603,  0.6484]) [PAD]\n",
      "tensor([14.1934,  0.6531, -0.2064]) [PAD]\n",
      "tensor([13.0712,  1.8187,  0.2361]) [PAD]\n",
      "tensor([13.2313,  1.1596,  0.3507]) [PAD]\n",
      "tensor([13.5008,  0.6169,  0.2383]) [PAD]\n",
      "tensor([13.8909,  0.4174, -0.5245]) [PAD]\n",
      "tensor([13.9278, -0.2196, -0.9259]) [PAD]\n",
      "tensor([14.4523, -0.5629, -0.7464]) [PAD]\n",
      "tensor([14.9401,  0.6581,  0.3584]) [PAD]\n",
      "tensor([14.6854,  0.8815,  0.5193]) [PAD]\n",
      "tensor([13.8892,  3.0316,  2.2010]) ㅅ\n",
      "tensor([12.9898,  4.7764,  2.1064]) ㅅ\n",
      "tensor([12.4195,  1.9726,  1.9559]) ㅓ\n",
      "tensor([14.8119,  2.5387,  0.4654]) [PAD]\n",
      "tensor([14.9663,  3.6826, -0.6118]) [PAD]\n",
      "tensor([14.8245,  3.8650, -1.0412]) [PAD]\n",
      "tensor([14.1845,  5.5710, -0.9412]) [PAD]\n",
      "tensor([13.2673,  3.2142,  2.5330]) ㅇ\n",
      "tensor([10.6634,  8.9831,  0.3749]) [PAD]\n",
      "tensor([14.4379,  1.6508, -0.4993]) [PAD]\n",
      "tensor([12.2520,  6.3991,  0.6595]) [PAD]\n",
      "tensor([10.0407,  9.8960, -0.0114])  \n",
      "tensor([14.8525,  2.6530,  0.5791]) [PAD]\n",
      "tensor([14.7115,  1.5175,  1.4173]) [PAD]\n",
      "tensor([14.9390,  1.5528,  0.4921]) [PAD]\n",
      "tensor([13.9700,  4.4677,  1.2212]) [PAD]\n",
      "tensor([13.3946,  2.7155,  1.6787]) ㅇ\n",
      "tensor([14.3429,  2.0388,  1.9076]) ㅣ\n",
      "tensor([15.6278,  2.1451,  0.7518]) [PAD]\n",
      "tensor([14.6237,  5.8169,  1.7496]) [PAD]\n",
      "tensor([12.9832,  3.5432,  1.9293]) ㄴ\n",
      "tensor([14.3370,  3.0133,  2.9138]) [PAD]\n",
      "tensor([14.6427,  2.2309, -0.3358]) [PAD]\n",
      "tensor([14.6182,  1.6326,  0.0395]) [PAD]\n",
      "tensor([14.2725,  1.4169,  0.7631]) [PAD]\n",
      "tensor([13.9051,  2.1432, -0.1048]) [PAD]\n",
      "tensor([14.6638,  0.8322,  0.1555]) [PAD]\n",
      "tensor([14.2812,  0.3944,  0.1468]) [PAD]\n",
      "tensor([14.3086,  0.9385,  0.0398]) [PAD]\n",
      "tensor([13.9590,  3.6908,  3.5345]) ㅅ\n",
      "tensor([10.4349,  9.7398,  0.2173]) [PAD]\n",
      "tensor([14.2466,  3.5006,  0.7150]) ㅣ\n",
      "tensor([13.1255,  4.5025,  2.3422]) [PAD]\n",
      "tensor([13.2006,  2.8454,  1.9663]) [PAD]\n",
      "tensor([6.4773, 6.3348, 3.3813]) ㄱ\n",
      "tensor([5.6044, 4.1892, 4.1194]) ㄱ\n",
      "tensor([6.5687, 3.5746, 3.3746]) [PAD]\n",
      "tensor([9.7176, 3.5451, 2.0363]) [PAD]\n",
      "tensor([8.0443, 7.9538, 4.8815]) ㅌ\n",
      "tensor([10.0276,  6.5274,  3.7905]) ㅔ\n",
      "tensor([11.3953,  2.9201,  2.3561]) [PAD]\n",
      "tensor([9.6338, 3.4605, 2.8428]) [PAD]\n",
      "tensor([5.8081, 5.3214, 3.8230]) [PAD]\n",
      "tensor([9.2760, 2.9698, 2.9117]) [PAD]\n",
      "tensor([7.4542, 4.2488, 4.0333]) [PAD]\n",
      "tensor([9.6484, 3.4731, 2.3751]) [PAD]\n",
      "tensor([9.0085, 3.5775, 2.9936]) [PAD]\n",
      "tensor([9.5383, 3.2509, 1.8966]) [PAD]\n",
      "tensor([10.3695,  2.4207,  1.3099]) [PAD]\n",
      "tensor([9.6148, 4.6148, 1.5427]) [PAD]\n",
      "tensor([10.7080,  4.0876,  2.7779]) ㅅ\n",
      "tensor([12.5813,  4.4004,  3.6515]) ㅡ\n",
      "tensor([14.1528,  2.7416,  0.8302]) [PAD]\n",
      "tensor([12.7642,  3.7334,  0.1972]) [PAD]\n",
      "tensor([12.4925,  3.1946,  0.0280]) [PAD]\n",
      "tensor([13.0695,  1.6971,  0.6567]) [PAD]\n",
      "tensor([12.8597,  1.9130, -0.4811]) [PAD]\n",
      "tensor([11.9576,  2.0303, -0.3955]) [PAD]\n",
      "tensor([10.9085,  2.8422,  0.9732]) [PAD]\n",
      "tensor([11.6859,  3.1977,  0.8266]) [PAD]\n",
      "tensor([8.3285, 3.5761, 2.1191]) ㅌ\n",
      "tensor([9.4184, 6.4692, 1.9980]) [PAD]\n",
      "tensor([13.1370,  2.5924,  1.8741]) ㅡ\n",
      "tensor([14.0704,  1.2917,  1.1415]) [PAD]\n",
      "tensor([14.1774,  3.2771,  0.7864]) [PAD]\n",
      "tensor([13.2860,  0.2263,  0.0575]) [PAD]\n",
      "tensor([10.6299,  1.0935,  0.8377]) [PAD]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sorted_tensor, indices = torch.sort(logits, dim=2, descending=True)\n",
    "\n",
    "outputs = list()\n",
    "for i,v in enumerate(indices[0]):\n",
    "    outputs.append(processor.tokenizer.convert_ids_to_tokens(v[0].item()))\n",
    "for i,v in enumerate(outputs):\n",
    "    print(sorted_tensor[0][i][:3],v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: 1\n",
      "Sample rate: 16000\n",
      "Duration:  1.637\n",
      "Bit depth: 2 bits\n",
      "len samples: 26192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <audio controls>\n",
       "                        <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\"/>\n",
       "                        Your browser does not support the audio element.\n",
       "                    </audio>\n",
       "                  "
      ],
      "text/plain": [
       "<pydub.audio_segment.AudioSegment at 0x1fb2e1c2390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word :  ㅇ start_offset : 0.0 end_offset : 0.02\n",
      "word :  ㅡ start_offset : 0.02 end_offset : 0.04\n",
      "word :  ㅁ start_offset : 0.06 end_offset : 0.08\n",
      "word :  ㅅ start_offset : 0.28 end_offset : 0.32\n",
      "word :  ㅓ start_offset : 0.32 end_offset : 0.34\n",
      "word :  ㅇ start_offset : 0.42 end_offset : 0.44\n",
      "word :    start_offset : 0.5 end_offset : 0.52\n",
      "word :  ㅇ start_offset : 0.6 end_offset : 0.62\n",
      "word :  ㅣ start_offset : 0.62 end_offset : 0.64\n",
      "word :  ㄴ start_offset : 0.68 end_offset : 0.7\n",
      "word :  ㅅ start_offset : 0.86 end_offset : 0.88\n",
      "word :  ㅣ start_offset : 0.9 end_offset : 0.92\n",
      "word :  ㄱ start_offset : 0.96 end_offset : 1.0\n",
      "word :  ㅌ start_offset : 1.04 end_offset : 1.06\n",
      "word :  ㅔ start_offset : 1.06 end_offset : 1.08\n",
      "word :  ㅅ start_offset : 1.28 end_offset : 1.3\n",
      "word :  ㅡ start_offset : 1.3 end_offset : 1.32\n",
      "word :  ㅌ start_offset : 1.48 end_offset : 1.5\n",
      "word :  ㅡ start_offset : 1.52 end_offset : 1.54\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predlogits = torch.argmax(logits, dim=-1)[0]\n",
    "\n",
    "\n",
    "outputs = processor.decode(predlogits,output_char_offsets=True)\n",
    "time_offset = model.config.inputs_to_logits_ratio / processor.feature_extractor.sampling_rate\n",
    "PrintAudioInfo(audio_input)\n",
    "for w in outputs['char_offsets']:\n",
    "    start_offset = round (w[ \"start_offset\" ] * time_offset, 2 )\n",
    "    end_offset = round (w[ \"end_offset\" ] * time_offset, 2 )\n",
    "    print('word : ',w['char'],'start_offset :',start_offset,'end_offset :',end_offset)\n",
    "    # display(audio_input[start_offset*1000:end_offset*1000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

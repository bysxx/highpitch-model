{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2a453c-f3cb-4c5c-897a-85b32f3f7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from librosa.util import normalize\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8313f3-b5ce-4e23-bc10-6f2638354d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_labels(json_folder_path):\n",
    "    pitch_labels = {}\n",
    "    for json_filename in os.listdir(json_folder_path):\n",
    "        if json_filename.endswith('.json'):\n",
    "            base_filename = json_filename[:-5]  # '.json' 확장자 제거\n",
    "            with open(os.path.join(json_folder_path, json_filename), 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "            pitch_labels[base_filename] = data['notes']\n",
    "    return pitch_labels\n",
    "\n",
    "def extract_single_label(notes):\n",
    "    if notes:\n",
    "        return notes[0]['midi_num']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd258bfd-36a1-4b29-876c-8f398a529f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_audio(audio_path, sr=22050, min_length=128):\n",
    "    audio, sr = librosa.load(audio_path, sr=sr)\n",
    "    audio = librosa.util.normalize(librosa.to_mono(audio))\n",
    "    \n",
    "    # 오디오 길이가 min_length보다 짧은 경우\n",
    "    if len(audio) < min_length:\n",
    "        audio = np.pad(audio, pad_width=(min_length - len(audio), 0), mode='constant')\n",
    "\n",
    "    return audio, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0654fa21-886a-4d20-a1af-5d86f211299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cqt_features(audio, sr=22050):\n",
    "    hop_length = max(1, len(audio) // 32)\n",
    "    if len(audio) < hop_length:\n",
    "        audio = np.pad(audio, pad_width=(0, hop_length - len(audio)), mode='constant')\n",
    "\n",
    "    CQT = np.abs(librosa.cqt(audio, sr=sr, hop_length=hop_length, n_bins=84, bins_per_octave=12))\n",
    "    CQT_db = librosa.amplitude_to_db(CQT, ref=np.max)\n",
    "    return CQT_db\n",
    "    \n",
    "def pad_cqt_features(cqt_features, max_length):\n",
    "    padding = max_length - cqt_features.shape[1]\n",
    "    if padding > 0:\n",
    "        return np.pad(cqt_features, ((0, 0), (0, padding)), mode='constant')\n",
    "    return cqt_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e3bfcf-8797-4b95-b137-7a0c66dc3c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(folder_path, json_folder_path, sr=22050):\n",
    "    features = []\n",
    "    labels = []\n",
    "    max_length = 0\n",
    "    pitch_labels = load_json_labels(json_folder_path)\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.lower().endswith('.wav'):\n",
    "            base_filename = file_name[:-4]  # '.wav' 확장자 제거\n",
    "            label_found = False\n",
    "\n",
    "            # JSON 레이블 키와 WAV 파일 이름 매치 확인\n",
    "            for label_key in pitch_labels.keys():\n",
    "                if base_filename.startswith(label_key):\n",
    "                    audio_path = os.path.join(folder_path, file_name)\n",
    "                    audio, sample_rate = load_and_preprocess_audio(audio_path, sr)\n",
    "                    if audio is not None:\n",
    "                        cqt_features = extract_cqt_features(audio, sample_rate)\n",
    "                        if cqt_features.shape[1] > max_length:\n",
    "                            max_length = cqt_features.shape[1]\n",
    "                        features.append(cqt_features)\n",
    "                        extracted_label = extract_single_label(pitch_labels[label_key])\n",
    "                        labels.append(extracted_label)\n",
    "                        label_found = True\n",
    "                        break\n",
    "            if not label_found:\n",
    "                print(f\"No label found for {file_name}\")\n",
    "\n",
    "    if features:\n",
    "        padded_features = np.array([np.pad(feature, ((0, 0), (0, max_length - feature.shape[1])), 'constant') for feature in features])\n",
    "        padded_features = np.expand_dims(padded_features, -1)\n",
    "    else:\n",
    "        print(\"No features collected\")\n",
    "\n",
    "    if labels:\n",
    "        labels = np.array(labels)\n",
    "    else:\n",
    "        print(\"No labels collected\")\n",
    "\n",
    "    return padded_features, labels, max_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd1c24-8209-45cf-afe0-5065e4ff3998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(16, kernel_size=2, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(2),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Conv2D(32, kernel_size=2, activation='relu'),\n",
    "        MaxPooling2D(2),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Conv2D(64, kernel_size=2, activation='relu'),\n",
    "        MaxPooling2D(2),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Conv2D(128, kernel_size=2, activation='relu'),\n",
    "        MaxPooling2D(2),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a3b48-856c-4adf-822f-9aa334236881",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'dataset\\\\Processed_Train_3'\n",
    "json_folder_path = 'dataset\\\\Labeling'\n",
    "features, labels, max_length = prepare_dataset(folder_path,json_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64119026-59d2-4b45-ae43-ecae3b5ae5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "categorical_labels = to_categorical(encoded_labels)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, categorical_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 모델 구성\n",
    "input_shape = X_train.shape[1:]  # 첫 번째 데이터의 모양으로 입력 형태를 설정\n",
    "num_classes = y_train.shape[1]  # 범주의 수\n",
    "model = build_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "model.summary()\n",
    "\n",
    "# 모델 평가\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Pre-training accuracy: %.4f%%' % (100 * score[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
